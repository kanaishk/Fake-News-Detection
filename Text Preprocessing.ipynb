{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ddf975-a9d7-4800-9440-8a91587f0a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, TweetTokenizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5826c-49e0-4669-8e7b-30e1b609c614",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29b5b60-706d-4f73-acf1-a248d4f55967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd,'Dataset')\n",
    "df = pd.read_csv(os.path.join(dataset_dir,'train_news_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e33213e-bb9a-44b1-96ca-b4f7bf791c31",
   "metadata": {},
   "source": [
    "Data- Description: There are 11 columns in the dataset provided to you. The description of each of the column is given below: \n",
    "“id”: Unique id of each news article \n",
    "“headline”: It is the title of the news. \n",
    "“written_by”: It represents the author of the news article\n",
    "“news”: It contains the full text of the news article \n",
    "“label”: It tells whether the news is fake (1) or not fake (0).\n",
    "\"headline_len\": length of headline\n",
    "\"news_len\": length of news article\n",
    "\"caps_in_headline\": number of capital letter in headline\n",
    "\"norm_caps_in_headline\": percentage of capital in headline\n",
    "\"caps_in_news\": number of capital letter in news article\n",
    "\"norm_caps_in_news\": percentage of capital in news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65e1742-498c-4744-9ee6-9a25143ddc10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (101, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515cb077-aa90-483c-99af-47ce06d3b131",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news</th>\n",
       "      <th>headline</th>\n",
       "      <th>label</th>\n",
       "      <th>headline_len</th>\n",
       "      <th>news_len</th>\n",
       "      <th>caps_in_headline</th>\n",
       "      <th>norm_caps_in_headline</th>\n",
       "      <th>caps_in_news</th>\n",
       "      <th>norm_caps_in_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107_Real.txt</td>\n",
       "      <td>See Liberal Facebook and Conservative Facebook...</td>\n",
       "      <td>Blue Feed Red Feed\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1151</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>32</td>\n",
       "      <td>0.027802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125_Real.txt</td>\n",
       "      <td>Contrary to the conventional wisdom saying tha...</td>\n",
       "      <td>\"It's Official \"\"Bernie Sanders Is Staying In ...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>7740</td>\n",
       "      <td>13</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>307</td>\n",
       "      <td>0.039664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152_Real.txt</td>\n",
       "      <td>An anonymous Jane Doe filed a federal lawsuit ...</td>\n",
       "      <td>Why The New Child Rape Case Filed Against Dona...</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>13675</td>\n",
       "      <td>14</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>376</td>\n",
       "      <td>0.027495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153_Real.txt</td>\n",
       "      <td>It came together in about a week. First, the i...</td>\n",
       "      <td>Pantsuit Power flashmob video for Hillary Clin...</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>5102</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>186</td>\n",
       "      <td>0.036456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115_Real.txt</td>\n",
       "      <td>Donald Trumps new campaign manager once insist...</td>\n",
       "      <td>Donald Trump's campaign manager says rape woul...</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2068</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>94</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               news  \\\n",
       "0  107_Real.txt  See Liberal Facebook and Conservative Facebook...   \n",
       "1  125_Real.txt  Contrary to the conventional wisdom saying tha...   \n",
       "2  152_Real.txt  An anonymous Jane Doe filed a federal lawsuit ...   \n",
       "3  153_Real.txt  It came together in about a week. First, the i...   \n",
       "4  115_Real.txt  Donald Trumps new campaign manager once insist...   \n",
       "\n",
       "                                            headline  label  headline_len  \\\n",
       "0                               Blue Feed Red Feed\\n      0            19   \n",
       "1  \"It's Official \"\"Bernie Sanders Is Staying In ...      0            79   \n",
       "2  Why The New Child Rape Case Filed Against Dona...      0            77   \n",
       "3  Pantsuit Power flashmob video for Hillary Clin...      0            86   \n",
       "4  Donald Trump's campaign manager says rape woul...      0            81   \n",
       "\n",
       "   news_len  caps_in_headline  norm_caps_in_headline  caps_in_news  \\\n",
       "0      1151                 4               0.210526            32   \n",
       "1      7740                13               0.164557           307   \n",
       "2     13675                14               0.181818           376   \n",
       "3      5102                 5               0.058140           186   \n",
       "4      2068                 2               0.024691            94   \n",
       "\n",
       "   norm_caps_in_news  \n",
       "0           0.027802  \n",
       "1           0.039664  \n",
       "2           0.027495  \n",
       "3           0.036456  \n",
       "4           0.045455  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c08f003-2749-481a-9a62-cd8e2c99abb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     101 non-null    object \n",
      " 1   news                   101 non-null    object \n",
      " 2   headline               101 non-null    object \n",
      " 3   label                  101 non-null    int64  \n",
      " 4   headline_len           101 non-null    int64  \n",
      " 5   news_len               101 non-null    int64  \n",
      " 6   caps_in_headline       101 non-null    int64  \n",
      " 7   norm_caps_in_headline  101 non-null    float64\n",
      " 8   caps_in_news           101 non-null    int64  \n",
      " 9   norm_caps_in_news      101 non-null    float64\n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 8.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e54494-c22c-4e6a-b539-065a669e9855",
   "metadata": {},
   "source": [
    "Clean Headline and News data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c988e66-11e9-4a11-a53e-60735e15a321",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425320e0-b320-496f-9f2c-3f31455f92f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_lists_of_strings(df, column):\n",
    "    \"\"\"Concatenate a series of lists of strings from a column in a dataframe\"\"\"\n",
    "    return [x for list_ in df[column].values for x in list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20b7a2d-8bda-4728-bca6-6b6721eafe73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_strings(string_, regex):\n",
    "    \"\"\"Find and Return a list of URLs in the input string\"\"\"\n",
    "    list_ = re.findall(regex, string_)\n",
    "    return [s[0] for s in list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d7f25e-6fdd-48cd-ba86-29257134f9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freq_dist_of_col(df, col):\n",
    "    \"\"\"Return a Frequency Distribution of a column\"\"\"\n",
    "    corpus_tokens = concat_lists_of_strings(df, col)\n",
    "    corpus_freq_dist = FreqDist(corpus_tokens)\n",
    "    print(f'The number of unique tokens in the corpus is {len(corpus_freq_dist)}')\n",
    "    return corpus_freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548965f0-2cd6-4f08-9a6f-6013ed2f097a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def review_freq_dis(df, col, n):\n",
    "    \"\"\"\n",
    "    Create a Frequency Distribution of a column of a dataframe and display\n",
    "    the n most common tokens.\n",
    "    \"\"\"\n",
    "    corpus_freq_dist = freq_dist_of_col(df, col)\n",
    "    display(corpus_freq_dist.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc002f0f-8eb0-498d-9694-609f88a91453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(word_list, punctuation_list):\n",
    "    \"\"\"Remove punctuation tokens from a list of tokens\"\"\"\n",
    "    return [w for w in word_list if w not in punctuation_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bfd3385-5fed-4abd-8604-205e1fade200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_single_characters(word_list, exception_list):\n",
    "    \"\"\"Remove all the single characters, except those on the exception list\"\"\"\n",
    "    return [w for w in word_list if (len(w) > 1 or w in exception_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a860613-2263-44c4-b169-6769d4778555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_words(word_list, words_to_remove):\n",
    "    \"\"\"Remove all the words in the words_to_remove list from the words_list\"\"\"\n",
    "    return [w for w in word_list if w not in words_to_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47dcdf4-08ce-499c-8314-b82726a68a02",
   "metadata": {},
   "source": [
    "Token Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d81bc340-375f-4bec-981b-5a5481451fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tknzr = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\([@\\w\\d]+\\)')\n",
    "df['news_tokens'] = df['news'].apply(tknzr.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ac2462-e490-4ea4-898d-e98eceb3af83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 11461\n"
     ]
    }
   ],
   "source": [
    "corpus_freq_dist = freq_dist_of_col(df, 'news_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85af8453-95b5-4a52-b052-6d5859829d42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3957),\n",
       " ('to', 2604),\n",
       " ('of', 2378),\n",
       " ('and', 2076),\n",
       " ('a', 2022),\n",
       " ('that', 1344),\n",
       " ('in', 1327),\n",
       " ('is', 1139),\n",
       " ('Trump', 863),\n",
       " ('for', 834),\n",
       " ('I', 646),\n",
       " ('on', 591),\n",
       " ('it', 591),\n",
       " ('he', 571),\n",
       " ('was', 563),\n",
       " ('not', 555),\n",
       " ('with', 550),\n",
       " ('his', 528),\n",
       " ('The', 510),\n",
       " ('as', 498),\n",
       " ('are', 492),\n",
       " ('be', 462),\n",
       " ('has', 436),\n",
       " ('have', 433),\n",
       " ('by', 422),\n",
       " ('Clinton', 382),\n",
       " ('this', 380),\n",
       " ('who', 356),\n",
       " ('they', 341),\n",
       " ('an', 336),\n",
       " ('from', 329),\n",
       " ('or', 329),\n",
       " ('about', 328),\n",
       " ('at', 327),\n",
       " ('you', 324),\n",
       " ('but', 313),\n",
       " ('Donald', 304),\n",
       " ('would', 301),\n",
       " ('people', 287),\n",
       " ('her', 285),\n",
       " ('s', 282),\n",
       " ('more', 266),\n",
       " ('will', 263),\n",
       " ('we', 258),\n",
       " ('all', 252),\n",
       " ('their', 235),\n",
       " ('she', 232),\n",
       " ('said', 225),\n",
       " ('Hillary', 224),\n",
       " ('one', 216),\n",
       " ('what', 210),\n",
       " ('He', 203),\n",
       " ('them', 198),\n",
       " ('But', 195),\n",
       " ('been', 192),\n",
       " ('like', 191),\n",
       " ('our', 189),\n",
       " ('so', 189),\n",
       " ('him', 188),\n",
       " ('than', 187),\n",
       " ('if', 186),\n",
       " ('had', 186),\n",
       " ('just', 184),\n",
       " ('were', 183),\n",
       " ('do', 179),\n",
       " ('when', 176),\n",
       " ('no', 173),\n",
       " ('Mr', 173),\n",
       " ('out', 172),\n",
       " ('can', 171),\n",
       " ('It', 166),\n",
       " ('which', 157),\n",
       " ('American', 155),\n",
       " ('time', 150),\n",
       " ('how', 149),\n",
       " ('We', 149),\n",
       " ('Republican', 146),\n",
       " ('know', 144),\n",
       " ('In', 143),\n",
       " ('campaign', 141),\n",
       " ('even', 140),\n",
       " ('because', 139),\n",
       " ('president', 137),\n",
       " ('up', 136),\n",
       " ('over', 135),\n",
       " ('And', 133),\n",
       " ('t', 131),\n",
       " ('other', 130),\n",
       " ('me', 128),\n",
       " ('its', 126),\n",
       " ('could', 126),\n",
       " ('This', 126),\n",
       " ('political', 124),\n",
       " ('these', 122),\n",
       " ('also', 119),\n",
       " ('my', 117),\n",
       " ('there', 116),\n",
       " ('only', 115),\n",
       " ('Former', 115),\n",
       " ('into', 111),\n",
       " ('think', 111),\n",
       " ('very', 110),\n",
       " ('those', 110),\n",
       " ('any', 109),\n",
       " ('some', 107),\n",
       " ('after', 107),\n",
       " ('did', 106),\n",
       " ('2016', 106),\n",
       " ('They', 106),\n",
       " ('former', 105),\n",
       " ('party', 104),\n",
       " ('years', 103),\n",
       " ('most', 101),\n",
       " ('Trumps', 101),\n",
       " ('get', 101),\n",
       " ('against', 100),\n",
       " ('way', 99),\n",
       " ('now', 99),\n",
       " ('New', 98),\n",
       " ('many', 97),\n",
       " ('Sanders', 96),\n",
       " ('country', 96),\n",
       " ('presidential', 95),\n",
       " ('candidate', 93),\n",
       " ('email', 93),\n",
       " ('A', 93),\n",
       " ('authoritarians', 92),\n",
       " ('then', 91),\n",
       " ('us', 91),\n",
       " ('support', 91),\n",
       " ('make', 90),\n",
       " ('If', 88),\n",
       " ('politics', 88),\n",
       " ('much', 87),\n",
       " ('too', 86),\n",
       " ('election', 85),\n",
       " ('say', 85),\n",
       " ('America', 85),\n",
       " ('first', 84),\n",
       " ('says', 80),\n",
       " ('being', 79),\n",
       " ('want', 79),\n",
       " ('You', 77),\n",
       " ('Bush', 77),\n",
       " ('dont', 76),\n",
       " ('your', 76),\n",
       " ('Clintons', 76),\n",
       " ('women', 76),\n",
       " ('told', 76),\n",
       " ('emails', 74)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_freq_dist.most_common(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aaa9d-4d41-4b29-8750-2222d25cdc41",
   "metadata": {},
   "source": [
    "Tokens used only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c55c9bb3-6a64-4050-85a0-ac592478a2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5498"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w in corpus_freq_dist.most_common() if w[1] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df89f49-c775-47d2-9a14-15453038fca7",
   "metadata": {},
   "source": [
    "Tokens used less than 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2317e765-13e5-4d2c-aa43-c5d0c512767d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9322"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w in corpus_freq_dist.most_common() if w[1] <= 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204aaf2-5730-4667-aaf1-88715878761e",
   "metadata": {},
   "source": [
    "At the top of the frequency distribution, the usual stop words are present, along with with words associated with politics or the names of political figures, institutions or countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e39f4f-6f3e-429c-a9f1-0f4e611e7747",
   "metadata": {},
   "source": [
    "The amount of words that are used only once or 5 or less times is relatively small given the size of the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db269bbd-1d6d-4880-80df-7ee3cc9d7457",
   "metadata": {},
   "source": [
    "Investigate if URLs are present in the news article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc60dffc-d736-4dad-9f3a-6b119c94d2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_REGEX = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e67904c-1ea5-464f-b172-4cac44ac2221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['news_urls'] = df['news'].apply(lambda x: find_strings(x, URL_REGEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e50e82d-2f55-49ff-9306-96d22c583924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_in_news = concat_lists_of_strings(df, 'news_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c12a138-221c-47b3-b034-1b1de1a74be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pic.twitter.com/kS8Z4dq9Qf']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_in_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c936bf-8aa1-4e61-912a-5fe8ab0f5558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_in_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc3e7762-ed04-4314-b000-5d6518331c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_freq_dist = FreqDist(urls_in_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbbdc80b-364e-4792-9e5a-afeb3b36802c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pic.twitter.com/kS8Z4dq9Qf', 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_freq_dist.most_common(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c35998-0fe9-438c-9e8e-f44cb39671f5",
   "metadata": {},
   "source": [
    "The first two links are mentioned multiple times but when I tried to check them out they were sealed. As more time goes on more of the links will stop working. So it would be better to replace them with a placeholder {link}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09f825f3-b3a6-464c-aa78-6c5c4c17a1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news'] = df['news'].apply(lambda x: re.sub(URL_REGEX, '{link}', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d4375-01b6-4b2b-907e-b7fcd7367a07",
   "metadata": {},
   "source": [
    "Investigate if URLs are present in the headline text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "716e26be-a41f-4bc1-b6cc-2996d43bd167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['headline_urls'] = df['headline'].apply(lambda x: find_strings(x, URL_REGEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0413a28-f064-4aed-8914-db5613dfaafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_in_headline = concat_lists_of_strings(df, 'headline_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c05734f8-d23c-4a60-bd15-f8386d69c646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_in_headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf2a16-cb19-4edf-afe3-b01efdbe009d",
   "metadata": {},
   "source": [
    "Replacing the links in the headlines with placeholder aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f6eb7f-e1c7-4f91-b887-39e6e5fab506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline'] = df['headline'].apply(lambda x: re.sub(URL_REGEX, '{link}', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd52b0a-7c08-4e6c-81b9-64f1c7b6f313",
   "metadata": {},
   "source": [
    "Investigate Twitter handles in news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380d7b45-3ccf-4815-84a9-04d5220bfa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TWITTER_HANDLE_REGEX = r'(?<=^|(?<=[^\\w]))(@\\w{1,15})\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cf82328-6531-4988-91b1-0d2f6c5a8f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['twitter_handles'] = df['clean_news'].apply(lambda x: re.findall(TWITTER_HANDLE_REGEX, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68a71856-2a9d-41e5-8a2a-9dd3250664fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_handles = concat_lists_of_strings(df, 'twitter_handles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92a7b316-e4d6-44c8-9665-7c83047f3f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_freq_dist = FreqDist(twitter_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae085249-146b-47ce-beec-fa3af3f18a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@AnnCompton', 1),\n",
       " ('@pastpunditry', 1),\n",
       " ('@Miller_Center', 1),\n",
       " ('@cyvault', 1),\n",
       " ('@FoxNews', 1),\n",
       " ('@DRUDGE', 1),\n",
       " ('@TLProfessor', 1),\n",
       " ('@WrongThinkBlog', 1),\n",
       " ('@VoxRomani', 1),\n",
       " ('@CNY_KFieLd', 1),\n",
       " ('@haydenchad20', 1),\n",
       " ('@harpandjoseph', 1),\n",
       " ('@austin_klavins', 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_freq_dist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6519d026-afa4-4f15-9cb6-50efdbb59fba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b846e01-a652-4585-8267-b4b1fc335dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c63e39e5-7783-4310-a30c-83239e2e9bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news'] = df['clean_news'].apply(lambda x: re.sub(TWITTER_HANDLE_REGEX, '@twitter-handle', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7a35d-b050-477e-b691-26ff2fbeb8f2",
   "metadata": {},
   "source": [
    "Capitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b0412-a425-4707-8f38-7464fe8df1ca",
   "metadata": {},
   "source": [
    "Because words with all caps are an import way that emphasis is made online, we will keep words that are in all caps while making all the letters in other words lower case. Words of length of one will be made lower case though since they are likely A or I which can be made lowercase without losing much emphasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0013be8-508b-4ac0-9bc0-cc0ab93f2963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lower_unless_all_caps(string_):\n",
    "    \"\"\"\n",
    "    Make all words in the input string lowercase unless that \n",
    "    word is in all caps\n",
    "    \"\"\"\n",
    "    words = string_.split()\n",
    "    processed_words = [w.lower() if not (w.isupper() and len(w) > 1) else w for w in words]\n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b053c44-ffa2-4b69-8071-8fa800eaa913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news'] = df['clean_news'].apply(lower_unless_all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "410e8b1b-dc6c-4390-bb75-c8193df83b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline'] = df['clean_headline'].apply(lower_unless_all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f220c19e-c114-484a-b46d-436da9341bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news</th>\n",
       "      <th>headline</th>\n",
       "      <th>label</th>\n",
       "      <th>headline_len</th>\n",
       "      <th>news_len</th>\n",
       "      <th>caps_in_headline</th>\n",
       "      <th>norm_caps_in_headline</th>\n",
       "      <th>caps_in_news</th>\n",
       "      <th>norm_caps_in_news</th>\n",
       "      <th>news_tokens</th>\n",
       "      <th>news_urls</th>\n",
       "      <th>clean_news</th>\n",
       "      <th>headline_urls</th>\n",
       "      <th>clean_headline</th>\n",
       "      <th>twitter_handles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107_Real.txt</td>\n",
       "      <td>See Liberal Facebook and Conservative Facebook...</td>\n",
       "      <td>Blue Feed Red Feed\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1151</td>\n",
       "      <td>4</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>32</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>[See, Liberal, Facebook, and, Conservative, Fa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>see liberal facebook and conservative facebook...</td>\n",
       "      <td>[]</td>\n",
       "      <td>blue feed red feed</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125_Real.txt</td>\n",
       "      <td>Contrary to the conventional wisdom saying tha...</td>\n",
       "      <td>\"It's Official \"\"Bernie Sanders Is Staying In ...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>7740</td>\n",
       "      <td>13</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>307</td>\n",
       "      <td>0.039664</td>\n",
       "      <td>[Contrary, to, the, conventional, wisdom, sayi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>contrary to the conventional wisdom saying tha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"it's official \"\"bernie sanders is staying in ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152_Real.txt</td>\n",
       "      <td>An anonymous Jane Doe filed a federal lawsuit ...</td>\n",
       "      <td>Why The New Child Rape Case Filed Against Dona...</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>13675</td>\n",
       "      <td>14</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>376</td>\n",
       "      <td>0.027495</td>\n",
       "      <td>[An, anonymous, Jane, Doe, filed, a, federal, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>an anonymous jane doe filed a federal lawsuit ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>why the new child rape case filed against dona...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153_Real.txt</td>\n",
       "      <td>It came together in about a week. First, the i...</td>\n",
       "      <td>Pantsuit Power flashmob video for Hillary Clin...</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>5102</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>186</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>[It, came, together, in, about, a, week, First...</td>\n",
       "      <td>[]</td>\n",
       "      <td>it came together in about a week. first, the i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>pantsuit power flashmob video for hillary clin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115_Real.txt</td>\n",
       "      <td>Donald Trumps new campaign manager once insist...</td>\n",
       "      <td>Donald Trump's campaign manager says rape woul...</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2068</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>94</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>[Donald, Trumps, new, campaign, manager, once,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>donald trumps new campaign manager once insist...</td>\n",
       "      <td>[]</td>\n",
       "      <td>donald trump's campaign manager says rape woul...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               news  \\\n",
       "0  107_Real.txt  See Liberal Facebook and Conservative Facebook...   \n",
       "1  125_Real.txt  Contrary to the conventional wisdom saying tha...   \n",
       "2  152_Real.txt  An anonymous Jane Doe filed a federal lawsuit ...   \n",
       "3  153_Real.txt  It came together in about a week. First, the i...   \n",
       "4  115_Real.txt  Donald Trumps new campaign manager once insist...   \n",
       "\n",
       "                                            headline  label  headline_len  \\\n",
       "0                               Blue Feed Red Feed\\n      0            19   \n",
       "1  \"It's Official \"\"Bernie Sanders Is Staying In ...      0            79   \n",
       "2  Why The New Child Rape Case Filed Against Dona...      0            77   \n",
       "3  Pantsuit Power flashmob video for Hillary Clin...      0            86   \n",
       "4  Donald Trump's campaign manager says rape woul...      0            81   \n",
       "\n",
       "   news_len  caps_in_headline  norm_caps_in_headline  caps_in_news  \\\n",
       "0      1151                 4               0.210526            32   \n",
       "1      7740                13               0.164557           307   \n",
       "2     13675                14               0.181818           376   \n",
       "3      5102                 5               0.058140           186   \n",
       "4      2068                 2               0.024691            94   \n",
       "\n",
       "   norm_caps_in_news                                        news_tokens  \\\n",
       "0           0.027802  [See, Liberal, Facebook, and, Conservative, Fa...   \n",
       "1           0.039664  [Contrary, to, the, conventional, wisdom, sayi...   \n",
       "2           0.027495  [An, anonymous, Jane, Doe, filed, a, federal, ...   \n",
       "3           0.036456  [It, came, together, in, about, a, week, First...   \n",
       "4           0.045455  [Donald, Trumps, new, campaign, manager, once,...   \n",
       "\n",
       "  news_urls                                         clean_news headline_urls  \\\n",
       "0        []  see liberal facebook and conservative facebook...            []   \n",
       "1        []  contrary to the conventional wisdom saying tha...            []   \n",
       "2        []  an anonymous jane doe filed a federal lawsuit ...            []   \n",
       "3        []  it came together in about a week. first, the i...            []   \n",
       "4        []  donald trumps new campaign manager once insist...            []   \n",
       "\n",
       "                                      clean_headline twitter_handles  \n",
       "0                                 blue feed red feed              []  \n",
       "1  \"it's official \"\"bernie sanders is staying in ...              []  \n",
       "2  why the new child rape case filed against dona...              []  \n",
       "3  pantsuit power flashmob video for hillary clin...              []  \n",
       "4  donald trump's campaign manager says rape woul...              []  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342596d1-865a-4118-98e5-ca1eeece768a",
   "metadata": {},
   "source": [
    "Number in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deaca15-47a4-49c7-9d07-fb13744c1968",
   "metadata": {},
   "source": [
    "I will replace the numbers with a space because some of the sentences run together and end with a number. Replacing the number with a space will split the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3c23d1f-d7fe-43aa-acb5-4df8a8ed14cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news'] = df['clean_news'].apply(lambda x: re.sub(r'9\\/11', 'nine-eleven', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "897ed542-1514-4d8a-8c60-245d4a4e3ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news'] = df['clean_news'].apply(lambda x: re.sub(r'\\d+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbf3f60e-3a17-43de-910e-4f85c945571e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline'] = df['clean_headline'].apply(lambda x: re.sub(r'9\\/11', 'nine-eleven', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b5a7774-163e-4ceb-84a1-3d588229dbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline'] = df['clean_headline'].apply(lambda x: re.sub(r'\\d+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2699aa4c-5a6f-4d0c-9e13-790c4351e44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f6e17-ae72-4f24-ace9-ad318f5cdc26",
   "metadata": {},
   "source": [
    "Tokens in the current clean news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59d49c73-9fa2-451f-9104-0b4e23a85a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news_tokens'] = df['clean_news'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7a367be-fffc-4887-a630-c55983d075cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 10511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5318),\n",
       " ('.', 4516),\n",
       " ('the', 4463),\n",
       " ('to', 2626),\n",
       " ('of', 2386),\n",
       " ('and', 2206),\n",
       " ('a', 2092),\n",
       " ('in', 1463),\n",
       " ('that', 1404),\n",
       " ('is', 1163),\n",
       " ('for', 874),\n",
       " ('trump', 859),\n",
       " ('he', 782),\n",
       " ('it', 757),\n",
       " ('on', 624),\n",
       " ('not', 600),\n",
       " ('i', 595),\n",
       " ('his', 575),\n",
       " ('was', 575),\n",
       " ('with', 560),\n",
       " ('as', 550),\n",
       " ('are', 512),\n",
       " ('but', 506),\n",
       " ('this', 506),\n",
       " ('be', 466),\n",
       " ('they', 447),\n",
       " ('has', 443),\n",
       " ('have', 440),\n",
       " ('by', 433),\n",
       " ('we', 408),\n",
       " ('you', 400),\n",
       " ('clinton', 381),\n",
       " ('who', 368),\n",
       " ('an', 350),\n",
       " (':', 343),\n",
       " ('at', 340),\n",
       " ('or', 340),\n",
       " ('from', 337),\n",
       " ('about', 335),\n",
       " ('``', 317),\n",
       " ('would', 313),\n",
       " ('?', 312),\n",
       " (\"''\", 311),\n",
       " ('donald', 304),\n",
       " ('her', 300),\n",
       " ('she', 299),\n",
       " ('people', 298),\n",
       " (\"'s\", 279),\n",
       " ('more', 276),\n",
       " ('if', 274),\n",
       " ('what', 274),\n",
       " ('will', 268),\n",
       " ('all', 266),\n",
       " ('when', 246),\n",
       " ('their', 244),\n",
       " ('one', 233),\n",
       " ('so', 233),\n",
       " ('said', 228),\n",
       " ('hillary', 227),\n",
       " ('do', 226),\n",
       " ('former', 220),\n",
       " ('no', 215),\n",
       " ('our', 212),\n",
       " ('president', 206),\n",
       " ('were', 199),\n",
       " ('can', 198),\n",
       " ('them', 198),\n",
       " ('just', 197),\n",
       " ('like', 196),\n",
       " ('(', 194),\n",
       " (')', 193),\n",
       " ('been', 192),\n",
       " ('had', 188),\n",
       " ('him', 188),\n",
       " ('than', 187),\n",
       " ('how', 185),\n",
       " ('its', 184),\n",
       " ('mr.', 172),\n",
       " ('out', 169),\n",
       " ('new', 160),\n",
       " ('there', 159),\n",
       " ('because', 158),\n",
       " ('which', 157),\n",
       " ('party', 153),\n",
       " ('these', 149),\n",
       " ('even', 149),\n",
       " ('american', 146),\n",
       " ('republican', 145),\n",
       " ('time', 143),\n",
       " ('over', 143),\n",
       " ('know', 142),\n",
       " ('campaign', 140),\n",
       " ('other', 137),\n",
       " ('my', 133),\n",
       " ('could', 132),\n",
       " (\"n't\", 131),\n",
       " ('up', 130),\n",
       " ('did', 128),\n",
       " ('me', 128),\n",
       " ('some', 127),\n",
       " ('political', 126),\n",
       " ('after', 125),\n",
       " ('only', 124),\n",
       " ('also', 124),\n",
       " ('now', 118),\n",
       " ('state', 117),\n",
       " ('many', 117),\n",
       " ('those', 116),\n",
       " ('most', 115),\n",
       " ('any', 113),\n",
       " ('think', 113),\n",
       " ('very', 112),\n",
       " ('into', 112),\n",
       " ('against', 105),\n",
       " ('white', 103),\n",
       " ('years', 103),\n",
       " ('trumps', 101),\n",
       " ('first', 101),\n",
       " ('way', 100),\n",
       " ('country', 97),\n",
       " ('get', 97),\n",
       " ('presidential', 96),\n",
       " ('national', 96),\n",
       " ('sanders', 95),\n",
       " (';', 95),\n",
       " ('make', 95),\n",
       " ('politics', 95),\n",
       " ('candidate', 92),\n",
       " ('email', 92),\n",
       " ('support', 92),\n",
       " ('us', 91),\n",
       " ('then', 90),\n",
       " ('much', 90),\n",
       " ('too', 88),\n",
       " ('authoritarians', 87),\n",
       " ('secretary', 85),\n",
       " ('election', 85),\n",
       " ('say', 85),\n",
       " ('does', 85),\n",
       " ('america', 85),\n",
       " ('emails', 81),\n",
       " ('says', 81),\n",
       " ('women', 80),\n",
       " ('dont', 79),\n",
       " ('your', 79),\n",
       " ('being', 79),\n",
       " ('want', 79),\n",
       " ('good', 79),\n",
       " ('told', 77),\n",
       " ('states', 77)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_freq_dis(df, 'clean_news_tokens', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a1ada-ecea-4005-9891-edaea22b7957",
   "metadata": {},
   "source": [
    "Removing all of the Punctuation tokens except for the exclamation point, because it seems like it may be an indicator of Fake news. Also removing all the single characters except for i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26ed002a-a14b-4060-b89c-d8f97d07733b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_news_tokens'] = df['clean_news_tokens'].apply(lambda x: remove_single_characters(x, ['i', '!']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d24db140-92b4-4cbb-af7e-acde67c2e097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 10466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 4463),\n",
       " ('to', 2626),\n",
       " ('of', 2386),\n",
       " ('and', 2206),\n",
       " ('in', 1463),\n",
       " ('that', 1404),\n",
       " ('is', 1163),\n",
       " ('for', 874),\n",
       " ('trump', 859),\n",
       " ('he', 782),\n",
       " ('it', 757),\n",
       " ('on', 624),\n",
       " ('not', 600),\n",
       " ('i', 595),\n",
       " ('his', 575),\n",
       " ('was', 575),\n",
       " ('with', 560),\n",
       " ('as', 550),\n",
       " ('are', 512),\n",
       " ('but', 506),\n",
       " ('this', 506),\n",
       " ('be', 466),\n",
       " ('they', 447),\n",
       " ('has', 443),\n",
       " ('have', 440),\n",
       " ('by', 433),\n",
       " ('we', 408),\n",
       " ('you', 400),\n",
       " ('clinton', 381),\n",
       " ('who', 368),\n",
       " ('an', 350),\n",
       " ('at', 340),\n",
       " ('or', 340),\n",
       " ('from', 337),\n",
       " ('about', 335),\n",
       " ('``', 317),\n",
       " ('would', 313),\n",
       " (\"''\", 311),\n",
       " ('donald', 304),\n",
       " ('her', 300),\n",
       " ('she', 299),\n",
       " ('people', 298),\n",
       " (\"'s\", 279),\n",
       " ('more', 276),\n",
       " ('if', 274),\n",
       " ('what', 274),\n",
       " ('will', 268),\n",
       " ('all', 266),\n",
       " ('when', 246),\n",
       " ('their', 244),\n",
       " ('one', 233),\n",
       " ('so', 233),\n",
       " ('said', 228),\n",
       " ('hillary', 227),\n",
       " ('do', 226),\n",
       " ('former', 220),\n",
       " ('no', 215),\n",
       " ('our', 212),\n",
       " ('president', 206),\n",
       " ('were', 199),\n",
       " ('can', 198),\n",
       " ('them', 198),\n",
       " ('just', 197),\n",
       " ('like', 196),\n",
       " ('been', 192),\n",
       " ('had', 188),\n",
       " ('him', 188),\n",
       " ('than', 187),\n",
       " ('how', 185),\n",
       " ('its', 184),\n",
       " ('mr.', 172),\n",
       " ('out', 169),\n",
       " ('new', 160),\n",
       " ('there', 159),\n",
       " ('because', 158),\n",
       " ('which', 157),\n",
       " ('party', 153),\n",
       " ('these', 149),\n",
       " ('even', 149),\n",
       " ('american', 146),\n",
       " ('republican', 145),\n",
       " ('time', 143),\n",
       " ('over', 143),\n",
       " ('know', 142),\n",
       " ('campaign', 140),\n",
       " ('other', 137),\n",
       " ('my', 133),\n",
       " ('could', 132),\n",
       " (\"n't\", 131),\n",
       " ('up', 130),\n",
       " ('did', 128),\n",
       " ('me', 128),\n",
       " ('some', 127),\n",
       " ('political', 126),\n",
       " ('after', 125),\n",
       " ('only', 124),\n",
       " ('also', 124),\n",
       " ('now', 118),\n",
       " ('state', 117),\n",
       " ('many', 117),\n",
       " ('those', 116),\n",
       " ('most', 115),\n",
       " ('any', 113),\n",
       " ('think', 113),\n",
       " ('very', 112),\n",
       " ('into', 112),\n",
       " ('against', 105),\n",
       " ('white', 103),\n",
       " ('years', 103),\n",
       " ('trumps', 101),\n",
       " ('first', 101),\n",
       " ('way', 100),\n",
       " ('country', 97),\n",
       " ('get', 97),\n",
       " ('presidential', 96),\n",
       " ('national', 96),\n",
       " ('sanders', 95),\n",
       " ('make', 95),\n",
       " ('politics', 95),\n",
       " ('candidate', 92),\n",
       " ('email', 92),\n",
       " ('support', 92),\n",
       " ('us', 91),\n",
       " ('then', 90),\n",
       " ('much', 90),\n",
       " ('too', 88),\n",
       " ('authoritarians', 87),\n",
       " ('secretary', 85),\n",
       " ('election', 85),\n",
       " ('say', 85),\n",
       " ('does', 85),\n",
       " ('america', 85),\n",
       " ('emails', 81),\n",
       " ('says', 81),\n",
       " ('women', 80),\n",
       " ('dont', 79),\n",
       " ('your', 79),\n",
       " ('being', 79),\n",
       " ('want', 79),\n",
       " ('good', 79),\n",
       " ('told', 77),\n",
       " ('states', 77),\n",
       " ('bush', 77),\n",
       " ('clintons', 76),\n",
       " ('news', 75),\n",
       " ('while', 75),\n",
       " ('bill', 75),\n",
       " ('see', 74),\n",
       " ('every', 74),\n",
       " ('representative', 74)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_freq_dis(df, 'clean_news_tokens', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a4c22-83a1-4c77-98b3-d87d70712a29",
   "metadata": {},
   "source": [
    "Tokens in the current clean headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "122f092f-4c75-4371-a757-bfd04b610a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline_tokens'] = df['clean_headline'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba7a62e7-8824-479c-a050-d4b605556085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('trump', 50),\n",
       " ('donald', 33),\n",
       " (\"''\", 32),\n",
       " ('the', 25),\n",
       " (\"'s\", 24),\n",
       " ('to', 24),\n",
       " ('clinton', 23),\n",
       " ('hillary', 19),\n",
       " ('``', 17),\n",
       " ('for', 17),\n",
       " ('is', 16),\n",
       " ('of', 13),\n",
       " ('in', 11),\n",
       " ('president', 11),\n",
       " ('.', 11),\n",
       " ('will', 10),\n",
       " ('and', 9),\n",
       " ('why', 8),\n",
       " ('says', 8),\n",
       " ('a', 8),\n",
       " ('he', 8),\n",
       " ('you', 7),\n",
       " ('i', 7),\n",
       " ('sanders', 6),\n",
       " ('be', 6),\n",
       " ('if', 6),\n",
       " ('america', 6),\n",
       " ('me', 6),\n",
       " ('not', 5),\n",
       " ('do', 5),\n",
       " (\"n't\", 5),\n",
       " ('american', 5),\n",
       " ('support', 5),\n",
       " ('campaign', 4),\n",
       " ('than', 4),\n",
       " ('time', 4),\n",
       " ('vote', 4),\n",
       " ('elected', 4),\n",
       " ('who', 4),\n",
       " ('rally', 4),\n",
       " ('this', 4),\n",
       " ('has', 4),\n",
       " ('!', 4),\n",
       " ('it', 3),\n",
       " ('rape', 3),\n",
       " ('against', 3),\n",
       " ('should', 3),\n",
       " ('women', 3),\n",
       " ('no', 3),\n",
       " ('would', 3),\n",
       " ('we', 3),\n",
       " ('more', 3),\n",
       " ('emails', 3),\n",
       " ('they', 3),\n",
       " ('leave', 3),\n",
       " ('CLINTON', 3),\n",
       " ('FOR', 3),\n",
       " ('how', 3),\n",
       " ('with', 3),\n",
       " ('as', 3),\n",
       " ('from', 3),\n",
       " ('$', 3),\n",
       " ('on', 3),\n",
       " ('just', 3),\n",
       " ('run', 3),\n",
       " ('election', 3),\n",
       " ('republican', 3),\n",
       " ('found', 3),\n",
       " ('email', 3),\n",
       " ('could', 3),\n",
       " ('ISIS', 3),\n",
       " ('my', 3),\n",
       " ('ted', 3),\n",
       " ('cruz', 3),\n",
       " ('BREAKING', 3),\n",
       " ('sarah', 3),\n",
       " ('palin', 3),\n",
       " ('feed', 2),\n",
       " ('official', 2),\n",
       " ('bernie', 2),\n",
       " ('new', 2),\n",
       " ('hear', 2),\n",
       " ('about', 2),\n",
       " ('by', 2),\n",
       " ('HILLARY', 2),\n",
       " ('our', 2),\n",
       " ('stop', 2),\n",
       " ('know', 2),\n",
       " ('people', 2),\n",
       " ('open', 2),\n",
       " ('don', 2),\n",
       " ('’', 2),\n",
       " ('t', 2),\n",
       " ('running', 2),\n",
       " ('mate', 2),\n",
       " ('last', 2),\n",
       " ('his', 2),\n",
       " ('confirms', 2),\n",
       " ('office', 2),\n",
       " ('revealed', 2),\n",
       " ('TRUMP', 2),\n",
       " ('million', 2),\n",
       " ('anyone', 2),\n",
       " ('left', 2),\n",
       " ('out', 2),\n",
       " ('I', 2),\n",
       " ('was', 2),\n",
       " ('trumps', 2),\n",
       " ('world', 2),\n",
       " ('FBI', 2),\n",
       " (\"'\", 2),\n",
       " ('tells', 2),\n",
       " ('rise', 2),\n",
       " ('moment', 2),\n",
       " ('politics', 2),\n",
       " ('like', 2),\n",
       " ('see', 2),\n",
       " ('honest', 2),\n",
       " ('endorses', 2),\n",
       " ('going', 2),\n",
       " ('millions', 2),\n",
       " ('here', 2),\n",
       " ('TO', 2),\n",
       " ('stacey', 2),\n",
       " ('dash', 2),\n",
       " ('does', 2),\n",
       " ('max', 2),\n",
       " ('lucado', 2),\n",
       " ('test', 2),\n",
       " ('have', 2),\n",
       " ('history', 2),\n",
       " ('at', 2),\n",
       " ('THE', 2),\n",
       " ('must', 2),\n",
       " ('bill', 2),\n",
       " ('sex', 2),\n",
       " ('an', 2),\n",
       " ('university', 2),\n",
       " ('another', 2),\n",
       " ('set', 2),\n",
       " ('testify', 2),\n",
       " ('dead', 2),\n",
       " ('vice', 2),\n",
       " ('marriage', 2),\n",
       " ('that', 2),\n",
       " ('wife', 2),\n",
       " ('had', 2),\n",
       " ('blue', 1),\n",
       " ('red', 1),\n",
       " ('staying', 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_freq_dis(df, 'clean_headline_tokens', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c99279-8206-4761-8d93-b725e3493f80",
   "metadata": {},
   "source": [
    "Remove Punctuation and Single Letter Tokens from Clean Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d0eb04a-54cb-45ac-8811-402c0cb447f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline_tokens'] = df['clean_headline_tokens'].apply(lambda x: remove_single_characters(x, ['i', '!']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c1d6150-b373-4b31-ab72-9a711ca35d81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('trump', 50),\n",
       " ('donald', 33),\n",
       " (\"''\", 32),\n",
       " ('the', 25),\n",
       " (\"'s\", 24),\n",
       " ('to', 24),\n",
       " ('clinton', 23),\n",
       " ('hillary', 19),\n",
       " ('``', 17),\n",
       " ('for', 17),\n",
       " ('is', 16),\n",
       " ('of', 13),\n",
       " ('in', 11),\n",
       " ('president', 11),\n",
       " ('will', 10),\n",
       " ('and', 9),\n",
       " ('why', 8),\n",
       " ('says', 8),\n",
       " ('he', 8),\n",
       " ('you', 7),\n",
       " ('i', 7),\n",
       " ('sanders', 6),\n",
       " ('be', 6),\n",
       " ('if', 6),\n",
       " ('america', 6),\n",
       " ('me', 6),\n",
       " ('not', 5),\n",
       " ('do', 5),\n",
       " (\"n't\", 5),\n",
       " ('american', 5),\n",
       " ('support', 5),\n",
       " ('campaign', 4),\n",
       " ('than', 4),\n",
       " ('time', 4),\n",
       " ('vote', 4),\n",
       " ('elected', 4),\n",
       " ('who', 4),\n",
       " ('rally', 4),\n",
       " ('this', 4),\n",
       " ('has', 4),\n",
       " ('!', 4),\n",
       " ('it', 3),\n",
       " ('rape', 3),\n",
       " ('against', 3),\n",
       " ('should', 3),\n",
       " ('women', 3),\n",
       " ('no', 3),\n",
       " ('would', 3),\n",
       " ('we', 3),\n",
       " ('more', 3),\n",
       " ('emails', 3),\n",
       " ('they', 3),\n",
       " ('leave', 3),\n",
       " ('CLINTON', 3),\n",
       " ('FOR', 3),\n",
       " ('how', 3),\n",
       " ('with', 3),\n",
       " ('as', 3),\n",
       " ('from', 3),\n",
       " ('on', 3),\n",
       " ('just', 3),\n",
       " ('run', 3),\n",
       " ('election', 3),\n",
       " ('republican', 3),\n",
       " ('found', 3),\n",
       " ('email', 3),\n",
       " ('could', 3),\n",
       " ('ISIS', 3),\n",
       " ('my', 3),\n",
       " ('ted', 3),\n",
       " ('cruz', 3),\n",
       " ('BREAKING', 3),\n",
       " ('sarah', 3),\n",
       " ('palin', 3),\n",
       " ('feed', 2),\n",
       " ('official', 2),\n",
       " ('bernie', 2),\n",
       " ('new', 2),\n",
       " ('hear', 2),\n",
       " ('about', 2),\n",
       " ('by', 2),\n",
       " ('HILLARY', 2),\n",
       " ('our', 2),\n",
       " ('stop', 2),\n",
       " ('know', 2),\n",
       " ('people', 2),\n",
       " ('open', 2),\n",
       " ('don', 2),\n",
       " ('running', 2),\n",
       " ('mate', 2),\n",
       " ('last', 2),\n",
       " ('his', 2),\n",
       " ('confirms', 2),\n",
       " ('office', 2),\n",
       " ('revealed', 2),\n",
       " ('TRUMP', 2),\n",
       " ('million', 2),\n",
       " ('anyone', 2),\n",
       " ('left', 2),\n",
       " ('out', 2),\n",
       " ('was', 2),\n",
       " ('trumps', 2),\n",
       " ('world', 2),\n",
       " ('FBI', 2),\n",
       " ('tells', 2),\n",
       " ('rise', 2),\n",
       " ('moment', 2),\n",
       " ('politics', 2),\n",
       " ('like', 2),\n",
       " ('see', 2),\n",
       " ('honest', 2),\n",
       " ('endorses', 2),\n",
       " ('going', 2),\n",
       " ('millions', 2),\n",
       " ('here', 2),\n",
       " ('TO', 2),\n",
       " ('stacey', 2),\n",
       " ('dash', 2),\n",
       " ('does', 2),\n",
       " ('max', 2),\n",
       " ('lucado', 2),\n",
       " ('test', 2),\n",
       " ('have', 2),\n",
       " ('history', 2),\n",
       " ('at', 2),\n",
       " ('THE', 2),\n",
       " ('must', 2),\n",
       " ('bill', 2),\n",
       " ('sex', 2),\n",
       " ('an', 2),\n",
       " ('university', 2),\n",
       " ('another', 2),\n",
       " ('set', 2),\n",
       " ('testify', 2),\n",
       " ('dead', 2),\n",
       " ('vice', 2),\n",
       " ('marriage', 2),\n",
       " ('that', 2),\n",
       " ('wife', 2),\n",
       " ('had', 2),\n",
       " ('blue', 1),\n",
       " ('red', 1),\n",
       " ('staying', 1),\n",
       " ('race', 1),\n",
       " ('concede', 1),\n",
       " ('child', 1),\n",
       " ('case', 1),\n",
       " ('filed', 1),\n",
       " ('ignored', 1),\n",
       " ('pantsuit', 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_freq_dis(df, 'clean_headline_tokens', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe257e66-6f45-4ad3-8bc4-6f515baf4d8b",
   "metadata": {},
   "source": [
    "Removing \"'s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd5e49-4a4c-4c61-bbc5-81e89c0b8ba4",
   "metadata": {},
   "source": [
    "While the fake news frequently or always didn't removed the apostrophe from 's, it doesn't look like that was done to the true news. 's will need to be removed so that it doesn't become a false indicator of true news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "740e92cf-cf32-4252-85db-39dd3cda4681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline_tokens'] = df['clean_headline_tokens'].apply(lambda x: remove_words(x, [\"'s\"]))\n",
    "df['clean_news_tokens'] = df['clean_news_tokens'].apply(lambda x: remove_words(x, [\"'s\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930acfc-953c-4bc5-917d-52fd9a90ef03",
   "metadata": {},
   "source": [
    "Remove Date Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefbb63-904e-4d8c-9a53-77273fef4cb2",
   "metadata": {},
   "source": [
    "To better generalize the models removing all the date words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec5ff400-a645-4a15-b4b4-d46b06b047da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_words = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', \n",
    "              'saturday', 'sunday', 'january', 'february', 'march', 'april',\n",
    "             'may', 'june', 'july', 'august', 'september', 'october',\n",
    "             'november', 'december']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "686fcdf8-80bf-4179-b000-70e29b9516c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clean_headline_tokens'] = df['clean_headline_tokens'].apply(lambda x: remove_words(x, date_words))\n",
    "df['clean_news_tokens'] = df['clean_news_tokens'].apply(lambda x: remove_words(x, date_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20c4b308-6140-4190-ac19-a36d42def9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d8bf9-e0d2-491b-b8fd-8bceced53114",
   "metadata": {},
   "source": [
    "Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ada8d7b-238f-4379-a070-24f688c13c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f22c7790-3391-4748-a880-5bea3ccd42ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74c5c75c-ea4f-4e25-a6ad-74af4093e359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the corpus is 10446\n"
     ]
    }
   ],
   "source": [
    "most_freq_clean_news = [x[0] for x in list(freq_dist_of_col(df, 'clean_news_tokens').most_common(150))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "768fbb0a-9c50-44d3-b2b4-12ed4a3e90c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'to',\n",
       " 'of',\n",
       " 'and',\n",
       " 'in',\n",
       " 'that',\n",
       " 'is',\n",
       " 'for',\n",
       " 'trump',\n",
       " 'he',\n",
       " 'it',\n",
       " 'on',\n",
       " 'not',\n",
       " 'i',\n",
       " 'his',\n",
       " 'was',\n",
       " 'with',\n",
       " 'as',\n",
       " 'are',\n",
       " 'but',\n",
       " 'this',\n",
       " 'be',\n",
       " 'they',\n",
       " 'has',\n",
       " 'have',\n",
       " 'by',\n",
       " 'we',\n",
       " 'you',\n",
       " 'clinton',\n",
       " 'who',\n",
       " 'an',\n",
       " 'at',\n",
       " 'or',\n",
       " 'from',\n",
       " 'about',\n",
       " '``',\n",
       " 'would',\n",
       " \"''\",\n",
       " 'donald',\n",
       " 'her',\n",
       " 'she',\n",
       " 'people',\n",
       " 'more',\n",
       " 'if',\n",
       " 'what',\n",
       " 'will',\n",
       " 'all',\n",
       " 'when',\n",
       " 'their',\n",
       " 'one',\n",
       " 'so',\n",
       " 'said',\n",
       " 'hillary',\n",
       " 'do',\n",
       " 'former',\n",
       " 'no',\n",
       " 'our',\n",
       " 'president',\n",
       " 'were',\n",
       " 'can',\n",
       " 'them',\n",
       " 'just',\n",
       " 'like',\n",
       " 'been',\n",
       " 'had',\n",
       " 'him',\n",
       " 'than',\n",
       " 'how',\n",
       " 'its',\n",
       " 'mr.',\n",
       " 'out',\n",
       " 'new',\n",
       " 'there',\n",
       " 'because',\n",
       " 'which',\n",
       " 'party',\n",
       " 'these',\n",
       " 'even',\n",
       " 'american',\n",
       " 'republican',\n",
       " 'time',\n",
       " 'over',\n",
       " 'know',\n",
       " 'campaign',\n",
       " 'other',\n",
       " 'my',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'up',\n",
       " 'did',\n",
       " 'me',\n",
       " 'some',\n",
       " 'political',\n",
       " 'after',\n",
       " 'only',\n",
       " 'also',\n",
       " 'now',\n",
       " 'state',\n",
       " 'many',\n",
       " 'those',\n",
       " 'most',\n",
       " 'any',\n",
       " 'think',\n",
       " 'very',\n",
       " 'into',\n",
       " 'against',\n",
       " 'white',\n",
       " 'years',\n",
       " 'trumps',\n",
       " 'first',\n",
       " 'way',\n",
       " 'country',\n",
       " 'get',\n",
       " 'presidential',\n",
       " 'national',\n",
       " 'sanders',\n",
       " 'make',\n",
       " 'politics',\n",
       " 'candidate',\n",
       " 'email',\n",
       " 'support',\n",
       " 'us',\n",
       " 'then',\n",
       " 'much',\n",
       " 'too',\n",
       " 'authoritarians',\n",
       " 'secretary',\n",
       " 'election',\n",
       " 'say',\n",
       " 'does',\n",
       " 'america',\n",
       " 'emails',\n",
       " 'says',\n",
       " 'women',\n",
       " 'dont',\n",
       " 'your',\n",
       " 'being',\n",
       " 'want',\n",
       " 'good',\n",
       " 'told',\n",
       " 'states',\n",
       " 'bush',\n",
       " 'clintons',\n",
       " 'news',\n",
       " 'while',\n",
       " 'bill',\n",
       " 'see',\n",
       " 'every',\n",
       " 'representative',\n",
       " 'under']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_clean_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80693b6c-58a4-45d5-a59c-a768dabe0bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    \"\"\"Return the intersection of two lists\"\"\"\n",
    "\n",
    "    temp = set(lst2) \n",
    "    lst3 = [value for value in lst1 if value in temp] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a537b2e4-d6ca-4edd-9434-6446070d5980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_words = intersection(stop_words, most_freq_clean_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05154743-3801-48d0-8b71-b4e2e15ac5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'we',\n",
       " 'our',\n",
       " 'you',\n",
       " 'your',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'she',\n",
       " 'her',\n",
       " 'it',\n",
       " 'its',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'into',\n",
       " 'after',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'over',\n",
       " 'under',\n",
       " 'then',\n",
       " 'there',\n",
       " 'when',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'no',\n",
       " 'not',\n",
       " 'only',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'now']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee5f8a49-6a9b-46d0-a5df-08bd9808a8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80bca9bd-277b-43b8-bd4c-33274cace3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ffaa363-5b38-428d-b963-8d40529ec615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def difference(lst1, lst2):\n",
    "    \"\"\"Return the difference of two lists\"\"\"\n",
    "\n",
    "    temp = set(lst2) \n",
    "    lst3 = [value for value in lst1 if value not in temp] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9e36eb8-fa24-4a8c-a910-45997e539de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words_in_nltk_not_news = difference(stop_words, most_freq_clean_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3f2b8e0-49e1-46ef-b6a6-21c189e0b970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myself',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'himself',\n",
       " \"she's\",\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'whom',\n",
       " \"that'll\",\n",
       " 'am',\n",
       " 'having',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'until',\n",
       " 'between',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'above',\n",
       " 'below',\n",
       " 'down',\n",
       " 'off',\n",
       " 'again',\n",
       " 'further',\n",
       " 'once',\n",
       " 'here',\n",
       " 'where',\n",
       " 'why',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'such',\n",
       " 'nor',\n",
       " 'own',\n",
       " 'same',\n",
       " 's',\n",
       " 't',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_nltk_not_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9615007-6be1-4a0b-bce0-dd222f9d2eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words_in_news_not_nltk = difference(most_freq_clean_news, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af8a6eb0-f1d8-44c7-9dbb-ec3a0cfbfabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump',\n",
       " 'clinton',\n",
       " '``',\n",
       " 'would',\n",
       " \"''\",\n",
       " 'donald',\n",
       " 'people',\n",
       " 'one',\n",
       " 'said',\n",
       " 'hillary',\n",
       " 'former',\n",
       " 'president',\n",
       " 'like',\n",
       " 'mr.',\n",
       " 'new',\n",
       " 'party',\n",
       " 'even',\n",
       " 'american',\n",
       " 'republican',\n",
       " 'time',\n",
       " 'know',\n",
       " 'campaign',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'political',\n",
       " 'also',\n",
       " 'state',\n",
       " 'many',\n",
       " 'think',\n",
       " 'white',\n",
       " 'years',\n",
       " 'trumps',\n",
       " 'first',\n",
       " 'way',\n",
       " 'country',\n",
       " 'get',\n",
       " 'presidential',\n",
       " 'national',\n",
       " 'sanders',\n",
       " 'make',\n",
       " 'politics',\n",
       " 'candidate',\n",
       " 'email',\n",
       " 'support',\n",
       " 'us',\n",
       " 'much',\n",
       " 'authoritarians',\n",
       " 'secretary',\n",
       " 'election',\n",
       " 'say',\n",
       " 'america',\n",
       " 'emails',\n",
       " 'says',\n",
       " 'women',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'good',\n",
       " 'told',\n",
       " 'states',\n",
       " 'bush',\n",
       " 'clintons',\n",
       " 'news',\n",
       " 'bill',\n",
       " 'see',\n",
       " 'every',\n",
       " 'representative']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_news_not_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ba5b5-b125-4003-ba36-daccc7e8e483",
   "metadata": {},
   "source": [
    "Looking at the remaining frequent words from the news text, that are all very concentrated on political news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fe40c-cdfc-4f0d-9ae6-9fb0419783c4",
   "metadata": {},
   "source": [
    "Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "974cc902-9b04-42cf-be64-28668501b105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(dataset_dir,'train_news_preprocessed_bf.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76706cbb-4f30-4916-bb83-2eab730be420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
