{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d5fa96-8bc7-49fd-b87a-15892e5285bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772a92b5-c71d-411a-abf5-0ee47e06d4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python311\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\python311\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python311\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\python311\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\python311\\lib\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\python311\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\python311\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gensim in c:\\python311\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python311\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\python311\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: textblob in c:\\python311\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\python311\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install gensim\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673add19-2dcf-45d2-b026-c5cfbe0aae63",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf81ae4-370d-4f36-9699-78cf42eea83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8ce3ac-afdc-434e-ba71-a5126f76d293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94890c7-049c-4f99-ab74-8644bc0747f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9caa3456-88f1-4e72-8291-23730b66129b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a20d65d-3a0d-4e0f-9f64-c8e7c4f518e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672d769-8c01-4377-b8ea-a30041dbdbc6",
   "metadata": {},
   "source": [
    "Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb514f4-9123-4aec-b9c8-973308b7ec04",
   "metadata": {},
   "source": [
    "Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577f3dc8-08c4-40cd-926d-82b71d62d7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd,'Dataset')\n",
    "test_df = pd.read_csv(os.path.join(dataset_dir,'test.tsv'), delimiter='\\t')\n",
    "train_df = pd.read_csv(os.path.join(dataset_dir,'train.tsv'), delimiter='\\t')\n",
    "valid_df = pd.read_csv(os.path.join(dataset_dir,'valid.tsv'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b6e751e-f86a-47f9-95d6-1d984c583190",
   "metadata": {
    "tags": []
   },
   "source": [
    "Understanding the dataset\n",
    "\n",
    "LIAR: A BENCHMARK DATASET FOR FAKE NEWS DETECTION\n",
    "\n",
    "William Yang Wang, \"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News Detection, to appear in Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017), short paper, Vancouver, BC, Canada, July 30-August 4, ACL.\n",
    "=====================================================================\n",
    "Description of the TSV format:\n",
    "\n",
    "Column 1: the ID of the statement ([ID].json).\n",
    "Column 2: the label.\n",
    "Column 3: the statement.\n",
    "Column 4: the subject(s).\n",
    "Column 5: the speaker.\n",
    "Column 6: the speaker's job title.\n",
    "Column 7: the state info.\n",
    "Column 8: the party affiliation.\n",
    "Column 9-13: the total credit history count, including the current statement.\n",
    "9: barely true counts.\n",
    "10: false counts.\n",
    "11: half true counts.\n",
    "12: mostly true counts.\n",
    "13: pants on fire counts.\n",
    "Column 14: the context (venue / location of the speech or statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59679ee3-e4c2-4b0c-bf36-a4ee1d5c735f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (1266, 14)\n",
      "Train dataset shape: (10239, 14)\n",
      "Validation dataset shape: (1283, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test dataset shape:\", test_df.shape)\n",
    "print(\"Train dataset shape:\", train_df.shape)\n",
    "print(\"Validation dataset shape:\", valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6ae2b4-d339-45e2-8508-6d767b58a564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.columns = ['ID', 'Label', 'Statement', 'Subject', 'Speaker', 'JobTitle', 'State', 'Party', \n",
    "                   'BarelyTrueCounts', 'FalseCounts', 'HalfTrueCounts', 'MostlyTrueCounts', 'PantsOnFireCounts', 'Context']\n",
    "\n",
    "train_df.columns = ['ID', 'Label', 'Statement', 'Subject', 'Speaker', 'JobTitle', 'State', 'Party', \n",
    "                    'BarelyTrueCounts', 'FalseCounts', 'HalfTrueCounts', 'MostlyTrueCounts', 'PantsOnFireCounts', 'Context']\n",
    "\n",
    "valid_df.columns = ['ID', 'Label', 'Statement', 'Subject', 'Speaker', 'JobTitle', 'State', 'Party', \n",
    "                    'BarelyTrueCounts', 'FalseCounts', 'HalfTrueCounts', 'MostlyTrueCounts', 'PantsOnFireCounts', 'Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee448098-5c9e-4f77-9be2-d09e521d4619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset null values:\n",
      " ID                     0\n",
      "Label                  0\n",
      "Statement              0\n",
      "Subject                0\n",
      "Speaker                0\n",
      "JobTitle             325\n",
      "State                262\n",
      "Party                  0\n",
      "BarelyTrueCounts       0\n",
      "FalseCounts            0\n",
      "HalfTrueCounts         0\n",
      "MostlyTrueCounts       0\n",
      "PantsOnFireCounts      0\n",
      "Context               17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test dataset null values:\\n',test_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f590e9-07f9-4f10-90cc-a1955cc82403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset null values:\n",
      " ID                      0\n",
      "Label                   0\n",
      "Statement               0\n",
      "Subject                 2\n",
      "Speaker                 2\n",
      "JobTitle             2897\n",
      "State                2208\n",
      "Party                   2\n",
      "BarelyTrueCounts        2\n",
      "FalseCounts             2\n",
      "HalfTrueCounts          2\n",
      "MostlyTrueCounts        2\n",
      "PantsOnFireCounts       2\n",
      "Context               102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset null values:\\n',train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80379bbd-fc21-4f63-9444-1a3c7d0b9fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset null values:\n",
      " ID                     0\n",
      "Label                  0\n",
      "Statement              0\n",
      "Subject                0\n",
      "Speaker                0\n",
      "JobTitle             345\n",
      "State                279\n",
      "Party                  0\n",
      "BarelyTrueCounts       0\n",
      "FalseCounts            0\n",
      "HalfTrueCounts         0\n",
      "MostlyTrueCounts       0\n",
      "PantsOnFireCounts      0\n",
      "Context               12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Valid dataset null values:\\n',valid_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e9c17-dc71-4e77-83eb-3e9a54505232",
   "metadata": {},
   "source": [
    "As there as no null values in 'Statement' feature which is our main feature we will proceed with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec13bdac-e4af-409d-9aa2-72edad3456fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\kanai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3111906-79fb-4273-aab0-03f31c8fdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4107dd5f-7828-42d3-88c0-1325c937f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CleanedStatement'] = train_df['Statement'].apply(clean_text)\n",
    "test_df['CleanedStatement'] = test_df['Statement'].apply(clean_text)\n",
    "valid_df['CleanedStatement'] = valid_df['Statement'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994d304b-e5c9-4599-8183-7f1b042cdd10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned statement: decline coal start started natural gas took started begin president george w. bush administration\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample cleaned statement:\", train_df['CleanedStatement'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8358d4-e758-4fca-8996-6db1614b4cec",
   "metadata": {},
   "source": [
    "Using Bag-of-Words different text vectorization techniques (CountVectorizer and TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7087feed-3612-4f6e-ad4d-b5e48781ba0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10680\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "train_cvectors = count_vectorizer.fit_transform(train_df['CleanedStatement'])\n",
    "print(len(count_vectorizer.get_feature_names()))\n",
    "test_cvectors = count_vectorizer.transform(test_df['CleanedStatement'])\n",
    "valid_cvectors = count_vectorizer.transform(valid_df['CleanedStatement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2593daa9-4908-4871-b4f4-c0c1a930b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training count vectors: (10239, 10680)\n",
      "Shape of test count vectors: (1266, 10680)\n",
      "Shape of validation count vectors: (1283, 10680)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training count vectors:\", train_cvectors.shape)\n",
    "print(\"Shape of test count vectors:\", test_cvectors.shape)\n",
    "print(\"Shape of validation count vectors:\", valid_cvectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84414ffe-2f72-4ccf-b9ba-bda267e6d98d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10680\n"
     ]
    }
   ],
   "source": [
    "termfreq_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_tvectors = termfreq_vectorizer.fit_transform(train_df['CleanedStatement'])\n",
    "print(len(termfreq_vectorizer.get_feature_names()))\n",
    "test_tvectors = termfreq_vectorizer.transform(test_df['CleanedStatement'])\n",
    "valid_tvectors = termfreq_vectorizer.transform(valid_df['CleanedStatement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80aaecf-cb0b-4c0b-a0b3-7f195264a032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training term frequency vectors: (10239, 10680)\n",
      "Shape of test term frequency vectors: (1266, 10680)\n",
      "Shape of validation term frequency vectors: (1283, 10680)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training term frequency vectors:\", train_tvectors.shape)\n",
    "print(\"Shape of test term frequency vectors:\", test_tvectors.shape)\n",
    "print(\"Shape of validation term frequency vectors:\", valid_tvectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18caff14-6de9-49a5-87f7-984c12dd5354",
   "metadata": {},
   "source": [
    "Making a word2vec model and word embedding for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f36da9d-49dc-4db7-8303-be320b41e4ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences = train_df['CleanedStatement'].apply(word_tokenize)\n",
    "\n",
    "model = Word2Vec(train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "model_dir = os.path.join(cwd,'Model')\n",
    "model.wv.save_word2vec_format(os.path.join(model_dir,'word2vec_liar_model.bin'), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e3c7c7-3049-40f1-a826-1ad367b02732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_embeddings = KeyedVectors.load_word2vec_format(os.path.join(model_dir,'word2vec_liar_model.bin'), binary=True)\n",
    "\n",
    "embedding_dim = word_embeddings.vector_size\n",
    "vocab_size = len(word_embeddings.key_to_index)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "word_to_index = {}\n",
    "\n",
    "for word, index in word_embeddings.key_to_index.items():\n",
    "    embedding_vector = word_embeddings.get_vector(word)\n",
    "    embedding_matrix[index] = embedding_vector\n",
    "    word_to_index[word] = index\n",
    "\n",
    "def text_to_indices(text):\n",
    "    indices = []\n",
    "    for word in text.split():\n",
    "        if word in word_to_index:\n",
    "            indices.append(word_to_index[word])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1169327-15a8-4d23-af87-80c3e3b3a69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_indices = train_df['CleanedStatement'].apply(text_to_indices)\n",
    "test_indices = test_df['CleanedStatement'].apply(text_to_indices)\n",
    "valid_indices = valid_df['CleanedStatement'].apply(text_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdc1ad-4ae7-44b6-a5f9-587eea7bcf56",
   "metadata": {},
   "source": [
    "Creating new features for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d60f0530-4b45-4315-8441-08413c033d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the statement\n",
    "train_df['StatementLength'] = train_df['CleanedStatement'].apply(lambda x: len(x.split()))\n",
    "test_df['StatementLength'] = test_df['CleanedStatement'].apply(lambda x: len(x.split()))\n",
    "valid_df['StatementLength'] = valid_df['CleanedStatement'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf281410-a923-4935-ac61-00c96be4079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presence of specific keywords or phrases\n",
    "keywords = ['fake', 'hoax']\n",
    "for keyword in keywords:\n",
    "    train_df[keyword] = train_df['CleanedStatement'].str.contains(keyword, case=False).astype(int)\n",
    "    test_df[keyword] = test_df['CleanedStatement'].str.contains(keyword, case=False).astype(int)\n",
    "    valid_df[keyword] = valid_df['CleanedStatement'].str.contains(keyword, case=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfc60a2-c29d-48c4-99b4-c1b8493d0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment scores\n",
    "train_df['SentimentScore'] = train_df['CleanedStatement'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test_df['SentimentScore'] = test_df['CleanedStatement'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "valid_df['SentimentScore'] = valid_df['CleanedStatement'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16abdfb5-0cc4-48d5-bb36-40a2d8d793f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linguistic features\n",
    "train_df['PosTags'] = train_df['CleanedStatement'].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "test_df['PosTags'] = test_df['CleanedStatement'].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "valid_df['PosTags'] = valid_df['CleanedStatement'].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6ac17f-fec7-479a-977b-0d7c0cbc448a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Label', 'Statement', 'Subject', 'Speaker', 'JobTitle', 'State', 'Party', 'BarelyTrueCounts', 'FalseCounts', 'HalfTrueCounts', 'MostlyTrueCounts', 'PantsOnFireCounts', 'Context', 'CleanedStatement', 'StatementLength', 'fake', 'hoax', 'SentimentScore', 'PosTags']\n"
     ]
    }
   ],
   "source": [
    "print(list(train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afeb0787-e5a1-4402-850a-a27a39138e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarelyTrueCounts</th>\n",
       "      <th>FalseCounts</th>\n",
       "      <th>HalfTrueCounts</th>\n",
       "      <th>MostlyTrueCounts</th>\n",
       "      <th>PantsOnFireCounts</th>\n",
       "      <th>StatementLength</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10237.000000</td>\n",
       "      <td>10237.000000</td>\n",
       "      <td>10237.000000</td>\n",
       "      <td>10237.000000</td>\n",
       "      <td>10237.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.0</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.534336</td>\n",
       "      <td>13.287682</td>\n",
       "      <td>17.135391</td>\n",
       "      <td>16.435870</td>\n",
       "      <td>6.202012</td>\n",
       "      <td>11.258912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.021412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.974349</td>\n",
       "      <td>24.113808</td>\n",
       "      <td>35.847862</td>\n",
       "      <td>36.153089</td>\n",
       "      <td>16.129599</td>\n",
       "      <td>6.479540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.198455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BarelyTrueCounts   FalseCounts  HalfTrueCounts  MostlyTrueCounts  \\\n",
       "count      10237.000000  10237.000000    10237.000000      10237.000000   \n",
       "mean          11.534336     13.287682       17.135391         16.435870   \n",
       "std           18.974349     24.113808       35.847862         36.153089   \n",
       "min            0.000000      0.000000        0.000000          0.000000   \n",
       "25%            0.000000      0.000000        0.000000          0.000000   \n",
       "50%            2.000000      2.000000        3.000000          3.000000   \n",
       "75%           12.000000     12.000000       13.000000         11.000000   \n",
       "max           70.000000    114.000000      160.000000        163.000000   \n",
       "\n",
       "       PantsOnFireCounts  StatementLength     fake          hoax  \\\n",
       "count       10237.000000     10239.000000  10239.0  10239.000000   \n",
       "mean            6.202012        11.258912      0.0      0.000195   \n",
       "std            16.129599         6.479540      0.0      0.013975   \n",
       "min             0.000000         1.000000      0.0      0.000000   \n",
       "25%             0.000000         8.000000      0.0      0.000000   \n",
       "50%             1.000000        10.000000      0.0      0.000000   \n",
       "75%             5.000000        14.000000      0.0      0.000000   \n",
       "max           105.000000       368.000000      0.0      1.000000   \n",
       "\n",
       "       SentimentScore  \n",
       "count    10239.000000  \n",
       "mean         0.021412  \n",
       "std          0.198455  \n",
       "min         -1.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.050000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c8be03-8619-4617-952d-f04b5c8659af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarelyTrueCounts</th>\n",
       "      <th>FalseCounts</th>\n",
       "      <th>HalfTrueCounts</th>\n",
       "      <th>MostlyTrueCounts</th>\n",
       "      <th>PantsOnFireCounts</th>\n",
       "      <th>StatementLength</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.755924</td>\n",
       "      <td>13.452607</td>\n",
       "      <td>17.547393</td>\n",
       "      <td>16.907583</td>\n",
       "      <td>6.007109</td>\n",
       "      <td>11.589258</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.015841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.981072</td>\n",
       "      <td>23.961261</td>\n",
       "      <td>36.117022</td>\n",
       "      <td>36.513901</td>\n",
       "      <td>15.062162</td>\n",
       "      <td>11.201158</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.197356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BarelyTrueCounts  FalseCounts  HalfTrueCounts  MostlyTrueCounts  \\\n",
       "count       1266.000000  1266.000000     1266.000000       1266.000000   \n",
       "mean          11.755924    13.452607       17.547393         16.907583   \n",
       "std           18.981072    23.961261       36.117022         36.513901   \n",
       "min            0.000000     0.000000        0.000000          0.000000   \n",
       "25%            0.000000     0.000000        1.000000          1.000000   \n",
       "50%            3.000000     3.000000        3.000000          3.000000   \n",
       "75%           12.000000    16.750000       15.000000         14.000000   \n",
       "max           70.000000   114.000000      160.000000        163.000000   \n",
       "\n",
       "       PantsOnFireCounts  StatementLength         fake         hoax  \\\n",
       "count        1266.000000      1266.000000  1266.000000  1266.000000   \n",
       "mean            6.007109        11.589258     0.000790     0.000790   \n",
       "std            15.062162        11.201158     0.028105     0.028105   \n",
       "min             0.000000         1.000000     0.000000     0.000000   \n",
       "25%             0.000000         8.000000     0.000000     0.000000   \n",
       "50%             1.000000        10.000000     0.000000     0.000000   \n",
       "75%             6.000000        14.000000     0.000000     0.000000   \n",
       "max           105.000000       344.000000     1.000000     1.000000   \n",
       "\n",
       "       SentimentScore  \n",
       "count     1266.000000  \n",
       "mean         0.015841  \n",
       "std          0.197356  \n",
       "min         -1.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.050000  \n",
       "max          0.800000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18afb876-4996-46eb-90c8-db8cbb93ea07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarelyTrueCounts</th>\n",
       "      <th>FalseCounts</th>\n",
       "      <th>HalfTrueCounts</th>\n",
       "      <th>MostlyTrueCounts</th>\n",
       "      <th>PantsOnFireCounts</th>\n",
       "      <th>StatementLength</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "      <td>1283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.812938</td>\n",
       "      <td>13.843336</td>\n",
       "      <td>17.237724</td>\n",
       "      <td>16.608730</td>\n",
       "      <td>6.886984</td>\n",
       "      <td>11.242401</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.021658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.026730</td>\n",
       "      <td>24.553414</td>\n",
       "      <td>35.633825</td>\n",
       "      <td>35.977736</td>\n",
       "      <td>17.603286</td>\n",
       "      <td>4.504255</td>\n",
       "      <td>0.027918</td>\n",
       "      <td>0.027918</td>\n",
       "      <td>0.199413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BarelyTrueCounts  FalseCounts  HalfTrueCounts  MostlyTrueCounts  \\\n",
       "count       1283.000000  1283.000000     1283.000000       1283.000000   \n",
       "mean          11.812938    13.843336       17.237724         16.608730   \n",
       "std           19.026730    24.553414       35.633825         35.977736   \n",
       "min            0.000000     0.000000        0.000000          0.000000   \n",
       "25%            0.000000     0.500000        0.500000          0.000000   \n",
       "50%            3.000000     3.000000        3.000000          3.000000   \n",
       "75%           12.000000    17.000000       13.000000         12.000000   \n",
       "max           70.000000   114.000000      160.000000        163.000000   \n",
       "\n",
       "       PantsOnFireCounts  StatementLength         fake         hoax  \\\n",
       "count        1283.000000      1283.000000  1283.000000  1283.000000   \n",
       "mean            6.886984        11.242401     0.000779     0.000779   \n",
       "std            17.603286         4.504255     0.027918     0.027918   \n",
       "min             0.000000         2.000000     0.000000     0.000000   \n",
       "25%             0.000000         8.000000     0.000000     0.000000   \n",
       "50%             1.000000        11.000000     0.000000     0.000000   \n",
       "75%             5.000000        14.000000     0.000000     0.000000   \n",
       "max           105.000000        32.000000     1.000000     1.000000   \n",
       "\n",
       "       SentimentScore  \n",
       "count     1283.000000  \n",
       "mean         0.021658  \n",
       "std          0.199413  \n",
       "min         -1.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.066667  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08901839-9c2d-42cb-9b8b-e586834b2d81",
   "metadata": {},
   "source": [
    "Implementing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bb92899-cccc-4a63-a10b-ce093081b96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Selected features to be fed to models\n",
    "selected_features = ['StatementLength', 'SentimentScore', 'fake', 'hoax', 'PosTags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa9ca72-0ea6-4fb0-8c33-26227906ee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_df['Label']\n",
    "y_test = test_df['Label']\n",
    "y_valid = valid_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8a34006-f913-4755-8fca-396d86395a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df[selected_features]\n",
    "X_test = test_df[selected_features]\n",
    "X_valid = valid_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c484b-d3ba-4fbd-a5ee-77f9a5f8b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training feature matrix:\", X_train.shape)\n",
    "print(\"Shape of testing feature matrix:\", X_test.shape)\n",
    "print(\"Shape of validation feature matrix:\", X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04080a9-082f-4cf7-8b2f-61aba97b911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_valid = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4c7d0-fc2c-47ba-b333-018bd6f525a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Validation Accuracy:\", accuracy_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e149e4dc-4a8b-4584-aa2c-e4193382de8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10239, 10239), indices imply (10239, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test_c_cos_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(test_cvectors, test_cvectors)\n\u001b[0;32m      3\u001b[0m valid_c_cos_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(valid_cvectors, valid_cvectors)\n\u001b[1;32m----> 5\u001b[0m train_c_cos_sim_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_c_cos_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCountVectorCosineSimilarity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m test_c_cos_sim_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(test_c_cos_sim, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountVectorCosineSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m valid_c_cos_sim_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(valid_c_cos_sim, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountVectorCosineSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (10239, 10239), indices imply (10239, 1)"
     ]
    }
   ],
   "source": [
    "'''train_c_cos_sim = cosine_similarity(train_cvectors, train_cvectors)\n",
    "test_c_cos_sim = cosine_similarity(test_cvectors, test_cvectors)\n",
    "valid_c_cos_sim = cosine_similarity(valid_cvectors, valid_cvectors)\n",
    "\n",
    "train_c_cos_sim_df = pd.DataFrame(train_c_cos_sim, columns=['CountVectorCosineSimilarity'])\n",
    "test_c_cos_sim_df = pd.DataFrame(test_c_cos_sim, columns=['CountVectorCosineSimilarity'])\n",
    "valid_c_cos_sim_df = pd.DataFrame(valid_c_cos_sim, columns=['CountVectorCosineSimilarity'])\n",
    "\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), train_c_cos_sim_df], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), test_c_cos_sim_df], axis=1)\n",
    "X_valid = pd.concat([X_valid.reset_index(drop=True), valid_c_cos_sim_df], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79f7261f-dab0-48a5-b42f-5bed4d06f7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10239, 10239), indices imply (10239, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_c_cos_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(test_cvectors)\n\u001b[0;32m      9\u001b[0m valid_c_cos_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(valid_cvectors)\n\u001b[1;32m---> 11\u001b[0m train_c_cos_sim_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_c_cos_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCountVectorCosineSimilarity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m test_c_cos_sim_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(test_c_cos_sim, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountVectorCosineSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m valid_c_cos_sim_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(valid_c_cos_sim, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountVectorCosineSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (10239, 10239), indices imply (10239, 1)"
     ]
    }
   ],
   "source": [
    "'''train_t_cos_sim = cosine_similarity(train_tvectors, train_tvectors)\n",
    "test_t_cos_sim = cosine_similarity(test_tvectors, test_tvectors)\n",
    "valid_t_cos_sim = cosine_similarity(valid_tvectors, valid_tvectors)\n",
    "\n",
    "train_t_cos_sim_df = pd.DataFrame(train_t_cos_sim, columns=['TermFreqVectorCosineSimilarity'])\n",
    "test_t_cos_sim_df = pd.DataFrame(test_t_cos_sim, columns=['TermFreqVectorCosineSimilarity'])\n",
    "valid_t_cos_sim_df = pd.DataFrame(valid_t_cos_sim, columns=['TermFreqVectorCosineSimilarity'])\n",
    "\n",
    "X_train = pd.concat([X_train, train_t_cos_sim_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_t_cos_sim_df], axis=1)\n",
    "X_valid = pd.concat([X_valid, valid_t_cos_sim_df], axis=1)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
