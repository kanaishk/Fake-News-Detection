{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d177633-d796-46d6-aec5-9106b0f595de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7325a176-9246-42ba-803c-ca8e76e0e229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python311\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\python311\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python311\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80a19ba-ac49-44be-be92-7a24cfc4475a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2fd665-a475-4984-99d7-000852b246a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd7dd2b-c987-4d03-aa5d-ae43ac4f27be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90d8d0-5bcc-463e-995d-e30ff2e55b4b",
   "metadata": {},
   "source": [
    "<h3>Importing the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c17505-e491-45e9-9055-467a345da7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd,'Dataset')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40931ca9-d2d6-4942-b4b8-15a0be211e06",
   "metadata": {},
   "source": [
    "Data- Description: There are 11 columns in the dataset provided to you. The description of each of the column is given below: \n",
    "“id”: Unique id of each news article \n",
    "“headline”: It is the title of the news. \n",
    "“written_by”: It represents the author of the news article\n",
    "“news”: It contains the full text of the news article \n",
    "“label”: It tells whether the news is fake (1) or not fake (0).\n",
    "\"headline_len\": length of headline\n",
    "\"news_len\": length of news article\n",
    "\"caps_in_headline\": number of capital letter in headline\n",
    "\"norm_caps_in_headline\": percentage of capital in headline\n",
    "\"caps_in_news\": number of capital letter in news article\n",
    "\"norm_caps_in_news\": percentage of capital in news article\n",
    "\"news_tokens\": tokenized news article\n",
    "\"news_url\": urls in news article\n",
    "\"clean_news\": cleaned up news article\n",
    "\"headline_url\": urls in headlines\n",
    "\"clean_headline\": cleaned up news headline\n",
    "\"twitter_handles\": twitter handles in news article\n",
    "\"clean_news_tokens\": tokens of cleaned news article\n",
    "\"clean_headline_tokens\": tokens of cleaned headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a7909c-3d75-460f-a995-89b5b3dd11fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_dir,'train_news_preprocessed.csv'), low_memory=False, \n",
    "                 usecols = ['label','clean_news_tokens','clean_headline_tokens'])\n",
    "# 'headline','news','headline_len','news_len','caps_in_headline','caps_in_news',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6983e16-7615-4013-985d-650283a81055",
   "metadata": {},
   "source": [
    "<h3>Setting environment variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f46652-3d9b-40f7-9b26-d8417291494a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1973\n",
    "pd.options.display.max_seq_items = 20\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0226cd46-8fd3-4012-93d1-81ff46a8c21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (19865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b02a66d-24e6-4758-922a-0f64be144594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_news_tokens</th>\n",
       "      <th>clean_headline_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['WASHINGTON', 'in', 'sonny', 'perdue', 'telli...</td>\n",
       "      <td>['ethics', 'questions', 'dogged', 'agriculture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['HOUSTON', 'venezuela', 'had', 'plan', 'it', ...</td>\n",
       "      <td>['U.S.', 'must', 'dig', 'deep', 'to', 'stop', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['on', 'abc', 'this', 'week', 'while', 'discus...</td>\n",
       "      <td>['cotton', 'to', 'house', 'do', 'not', 'walk',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['AUGUSTA', 'me', 'the', 'beleaguered', 'repub...</td>\n",
       "      <td>['paul', 'lepage', 'besieged', 'maine', 'gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['finian', 'cunningham', 'has', 'written', 'ex...</td>\n",
       "      <td>['digital', 'nine-eleven', 'if', 'trump', 'wins']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                  clean_news_tokens  \\\n",
       "0      0  ['WASHINGTON', 'in', 'sonny', 'perdue', 'telli...   \n",
       "1      0  ['HOUSTON', 'venezuela', 'had', 'plan', 'it', ...   \n",
       "2      0  ['on', 'abc', 'this', 'week', 'while', 'discus...   \n",
       "3      0  ['AUGUSTA', 'me', 'the', 'beleaguered', 'repub...   \n",
       "4      1  ['finian', 'cunningham', 'has', 'written', 'ex...   \n",
       "\n",
       "                               clean_headline_tokens  \n",
       "0  ['ethics', 'questions', 'dogged', 'agriculture...  \n",
       "1  ['U.S.', 'must', 'dig', 'deep', 'to', 'stop', ...  \n",
       "2  ['cotton', 'to', 'house', 'do', 'not', 'walk',...  \n",
       "3  ['paul', 'lepage', 'besieged', 'maine', 'gover...  \n",
       "4  ['digital', 'nine-eleven', 'if', 'trump', 'wins']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e7c7de-4dbb-4d99-959c-c23ccf8e9e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19865 entries, 0 to 19864\n",
      "Data columns (total 3 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   label                  19865 non-null  int64 \n",
      " 1   clean_news_tokens      19865 non-null  object\n",
      " 2   clean_headline_tokens  19865 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 465.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a5708b-ad6b-4c65-b619-a6a7343df13d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10387\n",
       "1     9478\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bdf1680-bc43-450e-8ef8-e3d4c195eb5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.clean_news_tokens = df.clean_news_tokens.map(ast.literal_eval)\n",
    "df.clean_headline_tokens = df.clean_headline_tokens.map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcb0487-16ac-4665-bd80-423e21cd1c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.label\n",
    "X = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b867cb-cffe-412f-80e3-238c78c5f392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = RANDOM_STATE,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde2eae2-f4e7-4fa1-8573-a1a53b811e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15892, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827913ec-0f06-47ef-a79b-ec223fd35a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3973, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1dce3dc-0184-4274-b958-6189f83340e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f043c16-32f7-43e6-ba35-65adaacc7406",
   "metadata": {},
   "source": [
    "<h2>Train Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b3bcf7-a787-4151-9a32-e9614a7b8026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def passthrough(doc):\n",
    "    \"\"\"passthrough function for use in the pipeline because the text is already tokenized\"\"\"\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37715eab-c0a2-438d-bf33-96d812639902",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = os.path.join(cwd,'Graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76964ce5-6879-460a-a718-efccdec8ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confustion_matrix_and_classification_report(estimator, X, y, labels, set_name):\n",
    "    \"\"\"\n",
    "    Display a Classfication Report and Confusion Matrix for the given data.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = estimator.predict(X)\n",
    "    labels = ['true','false']\n",
    "    print(f'Classification Report for {set_name} Set')\n",
    "    print(classification_report(y, predictions, target_names=labels, digits=4))\n",
    "    \n",
    "    \"\"\"\n",
    "    matrix = plot_confusion_matrix(estimator,\n",
    "                                   X,\n",
    "                                   y,\n",
    "                                   display_labels = labels,\n",
    "                                   cmap = plt.cm.Blues,\n",
    "                                   xticks_rotation = 70,\n",
    "                                   values_format = 'd')\n",
    "    title=f'{set_name} Set Confustion Matrix, without Normalization'\n",
    "    matrix.ax_.set_title(title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    matrix = plot_confusion_matrix(estimator,\n",
    "                                   X,\n",
    "                                   y,\n",
    "                                   display_labels = labels,\n",
    "                                   cmap = plt.cm.Blues,\n",
    "                                   xticks_rotation = 70,\n",
    "                                   normalize = 'true')\n",
    "    titlen=f'{set_name} Set Confustion Matrix, with Normalization'\n",
    "    matrix.ax_.set_title(titlen)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b292a04-f9db-4da9-ab08-fa40500cc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "         self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c988d85-d6e0-4fb6-a354-ecbeb4f65709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(doc):\n",
    "    \"\"\"Remove the stopwords from the input document\"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [token for token in doc if ((token not in stop_words) and (token.lower() not in stop_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9778bb3-e443-4cba-9004-1d3bbf86a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_tokens(doc):\n",
    "    \"\"\"lowercase all letters in doc\"\"\"\n",
    "    return [token.lower() for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9bcef88-78c3-4930-887e-e1062f0788ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_and_remove_stopwords(doc):\n",
    "    \"\"\"Remove stopwords and lowercase tokens\"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [token.lower() for token in doc if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86f60e1d-6c52-49f8-a643-dfffa27303bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_model(X_train, X_test, y_train_enc, y_test_enc, classes_,\n",
    "                        preprocessor, tokenizer, stopwords, max_df=1.0, ngram_range = (1, 1)):\n",
    "    \"\"\"\n",
    "    Train and Evaluate and Bag of Words Representation with a Naive Bayes\n",
    "    classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(min_df = 5, \n",
    "                           stop_words = stopwords,\n",
    "                           preprocessor = preprocessor, \n",
    "                           tokenizer = tokenizer, \n",
    "                           max_df = max_df, \n",
    "                           ngram_range = ngram_range)),  \n",
    "    ('classifier', MultinomialNB()),\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train,y_train_enc)\n",
    "    \n",
    "    confustion_matrix_and_classification_report(pipeline, \n",
    "                                                X_train, \n",
    "                                                y_train_enc, \n",
    "                                                classes_, \n",
    "                                               'Training')\n",
    "\n",
    "    confustion_matrix_and_classification_report(pipeline, \n",
    "                                                X_test, \n",
    "                                                y_test_enc, \n",
    "                                                classes_,\n",
    "                                                'Test')\n",
    "    \"\"\"\n",
    "    fake_class_prob_sorted = pipeline['classifier'].feature_log_prob_[0, :].argsort()\n",
    "    true_class_prob_sorted = pipeline['classifier'].feature_log_prob_[1, :].argsort()\n",
    "    \n",
    "    print('fake ', np.take(pipeline['bow'].get_feature_names(), fake_class_prob_sorted[::-1][:25]))\n",
    "    print('')\n",
    "    print('true ', np.take(pipeline['bow'].get_feature_names(), true_class_prob_sorted[::-1][:25]))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a9d22-ed72-4ee0-aec6-b37f78723cf8",
   "metadata": {},
   "source": [
    "<h3>Headline only test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3277f9c2-ee3f-4870-b4bf-7473ad2ea103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9185    0.9468    0.9324      8310\n",
      "       false     0.9397    0.9079    0.9235      7582\n",
      "\n",
      "    accuracy                         0.9283     15892\n",
      "   macro avg     0.9291    0.9274    0.9280     15892\n",
      "weighted avg     0.9286    0.9283    0.9282     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.8894    0.9336    0.9110      2077\n",
      "       false     0.9230    0.8729    0.8973      1896\n",
      "\n",
      "    accuracy                         0.9046      3973\n",
      "   macro avg     0.9062    0.9032    0.9041      3973\n",
      "weighted avg     0.9055    0.9046    0.9044      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['clean_headline_tokens'], X_test['clean_headline_tokens'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, passthrough, passthrough, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec50ef8-f9e0-4b02-a1a1-8c78c7e260e4",
   "metadata": {},
   "source": [
    "<h3>News only test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "224c03ad-37f4-4410-b8f2-47531fc1b44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9352    0.9619    0.9483      8310\n",
      "       false     0.9568    0.9269    0.9416      7582\n",
      "\n",
      "    accuracy                         0.9452     15892\n",
      "   macro avg     0.9460    0.9444    0.9450     15892\n",
      "weighted avg     0.9455    0.9452    0.9451     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9093    0.9562    0.9322      2077\n",
      "       false     0.9491    0.8956    0.9216      1896\n",
      "\n",
      "    accuracy                         0.9273      3973\n",
      "   macro avg     0.9292    0.9259    0.9269      3973\n",
      "weighted avg     0.9283    0.9273    0.9271      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['clean_news_tokens'], X_test['clean_news_tokens'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, passthrough, passthrough, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effffa3d-7f76-457d-bdd9-2942280ee3e6",
   "metadata": {},
   "source": [
    "<h3>Headline and news test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1404810d-cb12-469a-b392-85167b8e7264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanai\\AppData\\Local\\Temp\\ipykernel_22940\\766617199.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['headline_and_news'] = X_train['clean_headline_tokens'] + X_train['clean_news_tokens']\n",
      "C:\\Users\\kanai\\AppData\\Local\\Temp\\ipykernel_22940\\766617199.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['headline_and_news'] = X_test['clean_headline_tokens'] + X_test['clean_news_tokens']\n"
     ]
    }
   ],
   "source": [
    "X_train['headline_and_news'] = X_train['clean_headline_tokens'] + X_train['clean_news_tokens']\n",
    "X_test['headline_and_news'] = X_test['clean_headline_tokens'] + X_test['clean_news_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7ba9a99-72eb-4049-a52c-96d99c4730c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9334    0.9659    0.9494      8310\n",
      "       false     0.9612    0.9244    0.9424      7582\n",
      "\n",
      "    accuracy                         0.9461     15892\n",
      "   macro avg     0.9473    0.9452    0.9459     15892\n",
      "weighted avg     0.9466    0.9461    0.9461     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9095    0.9586    0.9334      2077\n",
      "       false     0.9518    0.8956    0.9228      1896\n",
      "\n",
      "    accuracy                         0.9285      3973\n",
      "   macro avg     0.9307    0.9271    0.9281      3973\n",
      "weighted avg     0.9297    0.9285    0.9284      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, passthrough, passthrough, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262993a-89d4-4829-abaa-f56723ed2c9b",
   "metadata": {},
   "source": [
    "<h3>Headline and news article passed through LemmaTokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14d33e03-ecfe-4ce7-bdd3-4bcf8da0d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9293    0.9649    0.9467      8310\n",
      "       false     0.9598    0.9195    0.9392      7582\n",
      "\n",
      "    accuracy                         0.9432     15892\n",
      "   macro avg     0.9446    0.9422    0.9430     15892\n",
      "weighted avg     0.9439    0.9432    0.9432     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9076    0.9552    0.9308      2077\n",
      "       false     0.9480    0.8935    0.9199      1896\n",
      "\n",
      "    accuracy                         0.9257      3973\n",
      "   macro avg     0.9278    0.9243    0.9254      3973\n",
      "weighted avg     0.9269    0.9257    0.9256      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, passthrough, LemmaTokenizer(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18de618-ad95-4c47-8ff2-cdfcf6dcdef4",
   "metadata": {},
   "source": [
    "<h3>Headline and news article with stopwords removed</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c480d62-281f-418d-8f94-4e7aa06a9c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9374    0.9734    0.9551      8310\n",
      "       false     0.9696    0.9288    0.9487      7582\n",
      "\n",
      "    accuracy                         0.9521     15892\n",
      "   macro avg     0.9535    0.9511    0.9519     15892\n",
      "weighted avg     0.9528    0.9521    0.9521     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9115    0.9624    0.9363      2077\n",
      "       false     0.9562    0.8977    0.9260      1896\n",
      "\n",
      "    accuracy                         0.9315      3973\n",
      "   macro avg     0.9339    0.9301    0.9312      3973\n",
      "weighted avg     0.9328    0.9315    0.9314      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, passthrough, passthrough, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe51a79-db1f-48f0-9b1c-ad15a5bd591a",
   "metadata": {},
   "source": [
    "<h3>Headline and news article with stopwords removed and all lowercase</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ab81ee2-d0e3-41f9-8fb1-0610b5db8742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9343    0.9710    0.9523      8310\n",
      "       false     0.9668    0.9252    0.9455      7582\n",
      "\n",
      "    accuracy                         0.9492     15892\n",
      "   macro avg     0.9506    0.9481    0.9489     15892\n",
      "weighted avg     0.9498    0.9492    0.9491     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9089    0.9610    0.9342      2077\n",
      "       false     0.9544    0.8945    0.9235      1896\n",
      "\n",
      "    accuracy                         0.9293      3973\n",
      "   macro avg     0.9317    0.9278    0.9289      3973\n",
      "weighted avg     0.9306    0.9293    0.9291      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, lowercase_tokens, remove_stopwords, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215de55-5a58-4997-aa76-e0fbc69ea3fa",
   "metadata": {},
   "source": [
    "<h3>Headline and news article with stopwords removed, all lowercase and LemmaTokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ab8dd52-cdb4-4683-a7a6-e315588d87ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9315    0.9699    0.9503      8310\n",
      "       false     0.9655    0.9218    0.9431      7582\n",
      "\n",
      "    accuracy                         0.9470     15892\n",
      "   macro avg     0.9485    0.9459    0.9467     15892\n",
      "weighted avg     0.9477    0.9470    0.9469     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9059    0.9591    0.9317      2077\n",
      "       false     0.9521    0.8908    0.9204      1896\n",
      "\n",
      "    accuracy                         0.9265      3973\n",
      "   macro avg     0.9290    0.9249    0.9261      3973\n",
      "weighted avg     0.9279    0.9265    0.9263      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, lowercase_and_remove_stopwords, LemmaTokenizer(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea35c4c-fde5-422d-8366-adb8559cb1f2",
   "metadata": {},
   "source": [
    "<h3>Headline and news article with stopwords removed, all lowercase and LemmaTokenizer and ngram range (1,2)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24ecd38a-fa30-4fd9-9813-8d9ce2ffe1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9566    0.9901    0.9731      8310\n",
      "       false     0.9888    0.9508    0.9694      7582\n",
      "\n",
      "    accuracy                         0.9714     15892\n",
      "   macro avg     0.9727    0.9705    0.9713     15892\n",
      "weighted avg     0.9720    0.9714    0.9713     15892\n",
      "\n",
      "Classification Report for Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        true     0.9137    0.9793    0.9454      2077\n",
      "       false     0.9754    0.8987    0.9355      1896\n",
      "\n",
      "    accuracy                         0.9409      3973\n",
      "   macro avg     0.9446    0.9390    0.9404      3973\n",
      "weighted avg     0.9432    0.9409    0.9407      3973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_model(X_train['headline_and_news'], X_test['headline_and_news'], \n",
    "                     y_train_enc, y_test_enc, le.classes_, lowercase_and_remove_stopwords, LemmaTokenizer(), None, ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891796a4-12b7-477d-aac7-3b44575699d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
